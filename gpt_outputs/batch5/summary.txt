      bertscore_f1       CHRF     COMET
prompt  temperature                                   
prompt0 0.00             0.871418  61.050658  0.864899
        0.15             0.870212  60.798969  0.861883
        0.30             0.871704  61.176455  0.863603
        0.45             0.880840  61.786879  0.864891
        0.60             0.868809  60.408903  0.860988
        0.75             0.849263  52.188712  0.849778
prompt1 0.00             0.870439  60.741507  0.862836
        0.15             0.886204  64.162073  0.874134
        0.30             0.872794  61.607714  0.862597
        0.45             0.880365  65.374668  0.876538
        0.60             0.869362  60.403991  0.858788
        0.75             0.880160  61.863913  0.862373
prompt2 0.00             0.875766  62.844687  0.870973
        0.15             0.874405  62.528631  0.871247
        0.30             0.886726  64.095382  0.874347
        0.45             0.884621  63.466350  0.872671
        0.60             0.874488  62.543472  0.871422
        0.75             0.885904  64.855720  0.867832
prompt3 0.00             0.882597  63.307738  0.868017
        0.15             0.892231  67.080064  0.884158
        0.30             0.892371  66.996919  0.881701
        0.45             0.893063  67.551594  0.884263
        0.60             0.881790  62.544992  0.868419
        0.75             0.880995  62.508655  0.864782
prompt4 0.00             0.902439  71.596053  0.893558
        0.15             0.901192  71.515140  0.895365
        0.30             0.902460  71.569402  0.893103
        0.45             0.901167  70.940640  0.890548
        0.60             0.901930  71.566833  0.895220
        0.75             0.899693  70.740167  0.890909
Best (prompt, temperature) pair for each metric:
bertscore_f1: Prompt='prompt4', Temperature=0.3
CHRF: Prompt='prompt4', Temperature=0.0
COMET: Prompt='prompt4', Temperature=0.15

