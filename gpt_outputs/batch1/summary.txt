                     bertscore_f1       CHRF     COMET
prompt  temperature                                   
prompt0 0.00             0.881994  62.315044  0.865602
        0.15             0.872324  61.263567  0.864612
        0.30             0.870887  60.899781  0.861676
        0.45             0.869628  61.055073  0.863822
        0.60             0.885369  63.495717  0.872467
        0.75             0.873087  62.524928  0.867548
prompt1 0.00             0.871083  61.075790  0.863288
        0.15             0.881834  62.382005  0.864862
        0.30             0.875030  62.618359  0.872458
        0.45             0.880823  61.827543  0.863061
        0.60             0.879643  64.805990  0.880071
        0.75             0.865322  59.531398  0.876650
prompt2 0.00             0.876240  62.808511  0.872814
        0.15             0.875618  62.778789  0.872750
        0.30             0.883614  66.238864  0.878690
        0.45             0.882295  66.246888  0.877951
        0.60             0.879995  65.456594  0.879418
        0.75             0.884138  66.549759  0.879626
prompt3 0.00             0.891063  66.685946  0.883194
        0.15             0.893421  67.556675  0.885089
        0.30             0.884047  63.519257  0.870860
        0.45             0.898945  70.455693  0.890724
        0.60             0.894139  67.281225  0.886681
        0.75             0.889688  66.699310  0.874016
prompt4 0.00             0.902320  71.445074  0.895666
        0.15             0.900436  71.282079  0.891541
        0.30             0.899525  70.978629  0.894086
        0.45             0.901457  71.076850  0.891084
        0.60             0.900265  71.158088  0.892862
        0.75             0.899218  70.986798  0.887923
Best (prompt, temperature) pair for each metric:
bertscore_f1: Prompt='prompt4', Temperature=0.0
CHRF: Prompt='prompt4', Temperature=0.0
COMET: Prompt='prompt4', Temperature=0.0


